---
title: "Analyzing Pilot Results"
output:
  html_document:
    number_sections: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

# Setup

```{r load-data-define-variables}

rm(list=ls())

pacman::p_load(pacman,
               rio,
               tidyverse,
               rstatix,
               DT,
               kableExtra,
               readr,
               writexl,
               jsonlite,
               stringr,
               gridExtra,
               knitr,
               magrittr,
               pdist,
               gghighlight)


# Load the data ##########################
session_results_all_ptp <- import(
        './results/pilots/preprocessed_data/session_results_long_form.csv'
        )

session_results_all_ptp <- session_results_all_ptp %>%
        reorder_levels(condition, order = c('practice',
                                            'practice2',
                                            'schema_c',
                                            'schema_ic',
                                            'landmark_schema',
                                            'random_locations',
                                            'no_schema')
                       )


```

```{r define-parameters-load-functions}

# Load an external script which contains functions for estimating either just the learning rate, or also the asymptote
source('./scripts/utils/functions_for_fitting_learning_curves.R')

# Create parameters as starting points for estimations
a_start <- 0.5
c_start <- 0.1

# Create lower and upper bound constraints on the asymptote and learning rate
a_lower <- 0
a_upper <- 1
c_lower <- 0
c_upper <- 20
i_lower <- 0
i_upper <- 1

```

```{r exclude-qc-fail-participants}

# Exclude the one participant that did not pay attention to instructions
session_results_all_ptp <-
        session_results_all_ptp %>%
        filter(ptp != '609478fa9e5b4d075246cfaf') %>%
        droplevels()

```


```{r create-long-form-accuracy-type}

session_results_all_ptp_long_accuracy <- 
        session_results_all_ptp %>%
        pivot_longer(cols = starts_with("correct_"),
                     names_to = 'accuracy_type',
                     values_to = 'accuracy_value') %>%
        mutate(accuracy_type = as.factor(accuracy_type)) %>%
        reorder_levels(accuracy_type, order = c(
                'correct_exact',
                'correct_one_square_away',
                'correct_rad_21',
                'correct_rad_42',
                'correct_rad_63',
                'correct_rad_84',
                'correct_rad_105'
        ))
 
```

# Do all the calculations of all the dependent variables

Create a giant, long form data with dependent variables being performance on each of the 8 repetition of PAs. 
Factors will include:
- condition
- accuracy_type: i.e. how wide is the accuracy box/radius
- neighbor_status: is the dependent variable reflecting performance on the neighbor PAs, island PAs, or collapsed over them?

```{r order-of-conditions}

# For each participant, list the order of conditions
condition_orders <- tibble(.rows = 7)

all_ptp <- unique(session_results_all_ptp$ptp)

for (iPtp in as.vector(all_ptp)){
        iPtp
        condition_orders[iPtp] <-
                unique(
                        session_results_all_ptp$condition[
                                session_results_all_ptp$ptp==iPtp
                                ])
}

```

```{r create-one-large-long-form-for-image-repetitions}

mean_by_rep_long <- 
        session_results_all_ptp_long_accuracy %>%
        filter(!condition %in% c('practice','practice2')) %>%
        droplevels() %>%
        group_by(ptp_trunk,
                 condition,
                 new_pa_img_row_number_across_sessions,
                 accuracy_type) %>%
        summarize(correct_mean = mean(accuracy_value, na.rm = T),
                  correct_sd = sd(accuracy_value, na.rm = T),
                  correct_n = n()) %>%
        ungroup()


# Calculate mean for neighbor vs non neighbor
mean_by_landmark_rep_long <-
        session_results_all_ptp_long_accuracy %>%
        filter(!condition %in% c('practice','practice2')) %>%
        droplevels() %>%
        group_by(ptp_trunk,
                 condition,
                 adjascent_neighbor,
                 new_pa_img_row_number_across_sessions,
                 accuracy_type) %>%
        summarize(correct_mean = mean(accuracy_value, na.rm = T),
                  correct_sd = sd(accuracy_value, na.rm = T),
                  correct_n = as.numeric(n())) %>%
        ungroup() %>%
        mutate(across(c(correct_mean,
                        correct_sd,
                        correct_n),
                      ~ case_when(
                              is.na(adjascent_neighbor) ~ as.numeric(NA),
                              TRUE ~ .
                      )))


# Pivot into wide form, so we can later merge with the other data reflecting overall performance
mean_by_landmark_rep_long_wide <- mean_by_landmark_rep_long %>%
        filter(!condition %in% c('random_locations',
                                 'no_schema')) %>%
        droplevels() %>%
        pivot_wider(id_cols = c(ptp_trunk,
                                condition,
                                new_pa_img_row_number_across_sessions,
                                accuracy_type),
                    values_from = c(correct_mean,
                                    correct_sd,
                                    correct_n),
                    names_from = adjascent_neighbor,
                    names_prefix = 'neighbor_'
        )

# Now merge into one giant dataset
mean_by_rep_all_types <- merge(mean_by_rep_long,
                               mean_by_landmark_rep_long_wide,
                               by = c('ptp_trunk',
                                      'condition',
                                      'new_pa_img_row_number_across_sessions',
                                      'accuracy_type'),
                               all = TRUE)

# Pivot longer, but we have to do three columns, so break this up into two parts, then merge.
# Its possible to do this in one line, using names_pattern, but that needs complicated regular expressions
mean_by_rep_all_types_long_1 <-
        mean_by_rep_all_types %>%
        select(-contains(c('sd','correct_n'))) %>% 
        rename(both = correct_mean,
               island = correct_mean_neighbor_FALSE,
               neighbor = correct_mean_neighbor_TRUE) %>%
        pivot_longer(cols = c('both','island','neighbor'),
                     names_to = 'neighbor_status',
                     values_to = 'correct_mean',
                )
mean_by_rep_all_types_long_2 <-
        mean_by_rep_all_types %>%
        select(-contains(c('mean','correct_n'))) %>%
        rename(both = correct_sd,
               island = correct_sd_neighbor_FALSE,
               neighbor = correct_sd_neighbor_TRUE) %>%        
        pivot_longer(cols = c('both','island','neighbor'),
                     names_to = 'neighbor_status',
                     values_to = 'correct_sd',
                )

mean_by_rep_all_types_long_3 <-
        mean_by_rep_all_types %>%
        select(-contains(c('mean','sd'))) %>%
        rename(both = correct_n,
               island = correct_n_neighbor_FALSE,
               neighbor = correct_n_neighbor_TRUE) %>%        
        pivot_longer(cols = c('both','island','neighbor'),
                     names_to = 'neighbor_status',
                     values_to = 'n',
                )

mean_by_rep_all_types_long <-
        merge(mean_by_rep_all_types_long_1,
              
        merge(mean_by_rep_all_types_long_2,
              mean_by_rep_all_types_long_3,
              by = c('ptp_trunk',
                     'condition',
                     'new_pa_img_row_number_across_sessions',
                     'accuracy_type',
                     'neighbor_status')),
        
        by = c('ptp_trunk',
                     'condition',
                     'new_pa_img_row_number_across_sessions',
                     'accuracy_type',
                     'neighbor_status'))


# Add 95% CI for each calculation
mean_by_rep_all_types_long <- 
        mean_by_rep_all_types_long %>%
        mutate(ci_95 = 1.96*correct_sd/sqrt(n))


```

## Fit the learning curve, with intercept and learning rate

```{r all-learning-fits}

learning_and_intercept_each_participant <-
        mean_by_rep_all_types_long %>%
        filter(!(condition %in% c('no_schema','random_locations') & 
               neighbor_status %in% c('island','neighbor'))) %>%  # filter these, cause for those conditions there are no landmarks
        group_by(ptp_trunk,
                 condition,
                 neighbor_status,
                 accuracy_type) %>% 
        do(as.data.frame(
                optim(c(a_start,c_start),
                      fit_learning_and_intercept,
                      gr = NULL,
                      seq(1,8),
                      .$correct_mean,
                      'sse',
                      method = 'L-BFGS-B',
                      lower = c(i_lower,c_lower),
                      upper = c(i_upper,c_upper)
                )) %>%
                   mutate(id = row_number()) %>%
                   pivot_wider(names_from = id,
                               values_from = par,
                               names_prefix = 'par_')) %>%
        rename(sse = value,
               n_iterations = counts,
               i = par_1,
               c = par_2) %>%
        ungroup()

# Add the predicted data to the dataframe
learning_and_intercept_each_participants_y_hat <-
        learning_and_intercept_each_participant %>%
        group_by(ptp_trunk,
                 condition,
                 neighbor_status,
                 accuracy_type) %>% 
        mutate(y_hat_i_c = list(fit_learning_and_intercept(c(i,c),
                                                           seq(1:8),
                                                           seq(1:8),
                                                           'fit')),
               new_pa_img_row_number_across_sessions = list(seq(1:8))) %>%
        unnest(c(y_hat_i_c,
                 new_pa_img_row_number_across_sessions)) %>% 
        select(c(ptp_trunk,
                 condition,
                 neighbor_status,
                 accuracy_type,
                 y_hat_i_c,
                 new_pa_img_row_number_across_sessions)) %>%
        ungroup()

mean_by_rep_all_types_long <- merge(mean_by_rep_all_types_long,
                                    learning_and_intercept_each_participants_y_hat,
                                    by = c('ptp_trunk',
                                           'condition',
                                           'neighbor_status',
                                           'accuracy_type',
                                           'new_pa_img_row_number_across_sessions'),
                                    all = TRUE)


```

## Rough measures of learning: last 2 or last 4 reps of PAs

```{r rough-measures-each-participant}
last_two_reps_stats <-
mean_by_rep_all_types_long %>%
        filter(new_pa_img_row_number_across_sessions %in% c(7,8)) %>%
        group_by(ptp_trunk,
                 condition,
                 neighbor_status,
                 accuracy_type) %>%
        summarise(last_two_mean = mean(correct_mean),
                  last_two_sd   = sd(correct_sd)) %>%
        ungroup()

last_four_reps_stats <-
mean_by_rep_all_types_long %>%
        filter(new_pa_img_row_number_across_sessions %in% c(5,6,7,8)) %>%
        group_by(ptp_trunk,
                 condition,
                 neighbor_status,
                 accuracy_type) %>%
        summarise(last_four_mean = mean(correct_mean),
                  last_four_sd   = sd(correct_sd)) %>%
        ungroup()

# Create one variable, that will have all the dependent variables
sum_stats_each_participant <- merge(last_two_reps_stats,
                                    last_four_reps_stats,
                                    by = c('ptp_trunk',
                                           'condition',
                                           'neighbor_status',
                                           'accuracy_type'))

sum_stats_each_participant <- merge(sum_stats_each_participant,
                                    learning_and_intercept_each_participant,
                                    by = c('ptp_trunk',
                                           'condition',
                                           'neighbor_status',
                                           'accuracy_type'),
                                    all = TRUE)

```

# Plots

## Raw learning curves, without the fitted data

This is helpful to compare which accuracy radii to use.

Below, I plot only:

- correct_exact
- correct_rad_42
- correct_rad_63
- correct_one_square_away

We can see that, correct_exact is lowest, then comes correct_rad_42, and the correct_rad_63 and correct_one_square_away are almost exactly overlapping.

```{r raw-learning-curves-diff-accu-types, fig.width=10, fig.height=12, warning=FALSE, message=FALSE}

# NOT CORRECT, USING THE WRONG DATAFRAME

fig_long_accu <- mean_by_rep_all_types_long %>%
        filter(accuracy_type %in% c('correct_exact',
                                    'correct_one_square_away',
                                    'correct_rad_42',
                                    'correct_rad_63'),
               neighbor_status == 'both') %>%
        droplevels() %>%
        ggplot(aes(x=new_pa_img_row_number_across_sessions,
                   y=correct_mean,
                   color=accuracy_type)) +
        
        # Add the average across toys
        geom_point() +
        geom_line(size=1,
                  aes(linetype = accuracy_type)) +
        
        # # Add the average across landmark or not
        # geom_point(data = mean_by_landmark_rep, 
        #            aes(group=adjascent_neighbor,
        #                color=adjascent_neighbor,
        #                y=correct_rad_63_mean)) +
        # geom_line(data = mean_by_landmark_rep, 
        #           aes(group=adjascent_neighbor,
        #               color=adjascent_neighbor,
        #               y=correct_rad_63_mean),
        #           size=1) +
        # 
        facet_grid(ptp_trunk~condition) +
        ggtitle(paste('Various Accuracy types',sep='')) +
        theme(legend.position = 'top') +
        xlab('Image repetition') +
        scale_x_continuous(breaks=seq(1:8)) + 
        geom_vline(xintercept = 4.5, linetype = 'dashed')

print(fig_long_accu)


```


## Raw learning curves + learning fits

So, overlay the curve fits, with annotated into about the intercept value, learning rate value, and convergence status.
For the convergence status:

- 0 means success
- 52 means error.

Only plot correct_exact and then correct_one_square_away. Two separate plots for each.

Looking at those participants where the convergence failed, its unclear why it happens. For some of the failure cases, the data doesn't look messy or weird in any way. For example, participant '6047ae5...' random_locations condition.

```{r raw-learning-curves-and-fits, fig.width=13, fig.height=12}

# Plot the fits
fig_each_ptp <- mean_by_rep_all_types_long %>%
        filter(accuracy_type %in% c('correct_exact'),
               neighbor_status == 'both') %>%
        droplevels() %>%        
        ggplot(aes(x=new_pa_img_row_number_across_sessions,
                   y=correct_mean)) +
        geom_point() +
        geom_line(size=1) +

        # Add the y_hat learning and intercept
        geom_line(aes(x=new_pa_img_row_number_across_sessions,
                      y=y_hat_i_c),
                  size=1,
                  color='blue',
                  linetype = 'longdash') +

        facet_grid(ptp_trunk~condition) +
        ggtitle(paste('Exact correct: real and estimate data',sep='')) +
        xlab('Image repetition') +
        ylab('Correct Exact') +
        scale_x_continuous(breaks=c(1,2,3,4,5,6,7,8)) +
        # theme(legend.position = 'top') +
        geom_vline(xintercept = 4.5, linetype = 'dashed') +
        geom_text(data=filter(
                learning_and_intercept_each_participant,
                accuracy_type %in% c('correct_exact'),
                neighbor_status == 'both'
                ),
                aes(x=3.5,
                    y=0.65,
                    label = paste('conv=',
                                  as.character(convergence),
                                  ' ',
                                  'i=',
                                  as.character(round(i,2)),
                                  ' ',
                                  'c=',
                                  as.character(round(c,2)),
                                  seq='')))
        # geom_text(data=learning_only_each_participant,
        #           aes(x=7,y=0.05, label = paste('c=',as.character(round(c,2)),seq='')))        
        # annotate('text',x=1.5,y = 0.85, label = learning_and_asymptote_each_participant$a ,size=3)


print(fig_each_ptp)

# Now, plot with one square away

# Plot the fits
fig_each_ptp <- mean_by_rep_all_types_long %>%
        filter(accuracy_type %in% c('correct_one_square_away'),
               neighbor_status == 'both') %>%
        droplevels() %>%        
        ggplot(aes(x=new_pa_img_row_number_across_sessions,
                   y=correct_mean)) +
        geom_point() +
        geom_line(size=1) +

        # Add the y_hat learning and intercept
        geom_line(aes(x=new_pa_img_row_number_across_sessions,
                      y=y_hat_i_c),
                  size=1,
                  color='red',
                  linetype = 'longdash') +

        facet_grid(ptp_trunk~condition) +
        ggtitle(paste('One square away: real and estimate data',sep='')) +
        xlab('Image repetition') +
        ylab('Correct One Square Away') +
        scale_x_continuous(breaks=c(1,2,3,4,5,6,7,8)) +
        # theme(legend.position = 'top') +
        geom_vline(xintercept = 4.5, linetype = 'dashed') +
        geom_text(data=filter(
                learning_and_intercept_each_participant,
                accuracy_type %in% c('correct_one_square_away'),
                neighbor_status == 'both'
                ),
                aes(x=5.5,
                    y=0.15,
                    label = paste('conv=',
                                  as.character(convergence),
                                  ' ',
                                  'i=',
                                  as.character(round(i,2)),
                                  ' ',
                                  'c=',
                                  as.character(round(c,2)),
                                  seq='')))
        # geom_text(data=learning_only_each_participant,
        #           aes(x=7,y=0.05, label = paste('c=',as.character(round(c,2)),seq='')))        
        # annotate('text',x=1.5,y = 0.85, label = learning_and_asymptote_each_participant$a ,size=3)


print(fig_each_ptp)



```

## Learning curves: Landmark vs non-landmark

```{r landmark-raw-learning-curves-and-fits, fig.width=10, fig.height=12}

# Plot the fits
fig_each_ptp_lm <- mean_by_rep_all_types_long %>%
        filter(accuracy_type %in% c('correct_exact'),
               neighbor_status %in% c('island','neighbor'),
               !condition %in% c('random_locations','no_schema')) %>%
        droplevels() %>%        
        ggplot(aes(x=new_pa_img_row_number_across_sessions,
                   y=correct_mean,
                   group=neighbor_status,
                   color=neighbor_status)) +
        geom_point() +
        geom_line(size=1) +
# 
        # Add the y_hat learning and intercept
        geom_line(aes(x=new_pa_img_row_number_across_sessions,
                      y=y_hat_i_c),
                  size=1,
                  # color='blue',
                  linetype = 'longdash') +

        facet_grid(ptp_trunk~condition) +
        ggtitle(paste('Exact correct: real and estimate data',sep='')) +
        xlab('Image repetition') +
        ylab('Correct Exact') +
        scale_x_continuous(breaks=c(1,2,3,4,5,6,7,8)) +
        # theme(legend.position = 'top') +
        geom_vline(xintercept = 4.5, linetype = 'dashed') +
        geom_text(data=filter(
                learning_and_intercept_each_participant,
                accuracy_type %in% c('correct_exact'),
                neighbor_status %in% c('island','neighbor'),
                !condition %in% c('random_locations','no_schema')
                ),
                aes(x=3.5,
                    y=0.65,
                    label = paste('conv=',
                                  as.character(convergence),
                                  ' ',
                                  'i=',
                                  as.character(round(i,2)),
                                  ' ',
                                  'c=',
                                  as.character(round(c,2)),
                                  seq='')),
                position=ggstance::position_dodgev(height=0.3))
        # geom_text(data=learning_only_each_participant,
        #           aes(x=7,y=0.05, label = paste('c=',as.character(round(c,2)),seq='')))        
        # annotate('text',x=1.5,y = 0.85, label = learning_and_asymptote_each_participant$a ,size=3)


print(fig_each_ptp_lm)

# Plot the fits
fig_each_ptp_lm <- mean_by_rep_all_types_long %>%
        filter(accuracy_type %in% c('correct_one_square_away'),
               neighbor_status %in% c('island','neighbor'),
               !condition %in% c('random_locations','no_schema')) %>%
        droplevels() %>%        
        ggplot(aes(x=new_pa_img_row_number_across_sessions,
                   y=correct_mean,
                   group=neighbor_status,
                   color=neighbor_status)) +
        geom_point() +
        geom_line(size=1) +
# 
        # Add the y_hat learning and intercept
        geom_line(aes(x=new_pa_img_row_number_across_sessions,
                      y=y_hat_i_c),
                  size=1,
                  # color='blue',
                  linetype = 'longdash') +

        facet_grid(ptp_trunk~condition) +
        ggtitle(paste('correct_one_square_away: real and estimate data',sep='')) +
        xlab('Image repetition') +
        ylab('correct_one_square_away') +
        scale_x_continuous(breaks=c(1,2,3,4,5,6,7,8)) +
        # theme(legend.position = 'top') +
        geom_vline(xintercept = 4.5, linetype = 'dashed') +
        geom_text(data=filter(
                learning_and_intercept_each_participant,
                accuracy_type %in% c('correct_one_square_away'),
                neighbor_status %in% c('island','neighbor'),
                !condition %in% c('random_locations','no_schema')
                ),
                aes(x=3.5,
                    y=0.65,
                    label = paste('conv=',
                                  as.character(convergence),
                                  ' ',
                                  'i=',
                                  as.character(round(i,2)),
                                  ' ',
                                  'c=',
                                  as.character(round(c,2)),
                                  seq='')),
                position=ggstance::position_dodgev(height=0.3))
        # geom_text(data=learning_only_each_participant,
        #           aes(x=7,y=0.05, label = paste('c=',as.character(round(c,2)),seq='')))        
        # annotate('text',x=1.5,y = 0.85, label = learning_and_asymptote_each_participant$a ,size=3)


print(fig_each_ptp_lm)


```



## Rough measures

I think the last 2 reps is a better dependent variable, because it captures better the "final" state of learning.

Correct_one_square_away seems to be almost equivalent to correct_rad_63

I suggest we use the correct_exact and the correct_one_square_away measures.

```{r plot-rough-measures-overall, fig.width=13, fig.height=4}

sum_stats_each_participant %>%
        filter(neighbor_status == 'both') %>%
        droplevels() %>%
        ggplot(aes(x=condition,
                   y=last_two_mean)) +
        geom_violin() +
        geom_dotplot(binaxis = 'y',
                     stackdir = 'center',
                     stackratio = 1,
                     dotsize = 1,
                     fill = 'black',
                     alpha = 0.2) +
        geom_line(aes(group=ptp_trunk,
                      color=ptp_trunk)) +
        facet_wrap(~accuracy_type, nrow = 1) +
        stat_summary(fun=mean, geom="point", shape=20, size=5, 
                     color="blue", fill="blue") + 
        stat_summary(fun.data = mean_cl_normal,
                     geom = "errorbar",size=1,width=0.1,color='blue') +
        theme(legend.position = '') +
        theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
        ggtitle('Overall, last 2 reps') 

sum_stats_each_participant %>%
        filter(neighbor_status == 'both') %>%
        droplevels() %>%
        ggplot(aes(x=condition,
                   y=last_four_mean)) +
        geom_violin() +
        geom_dotplot(binaxis = 'y',
                     stackdir = 'center',
                     stackratio = 1,
                     dotsize = 1,
                     fill = 'black',
                     alpha = 0.2) +
        geom_line(aes(group=ptp_trunk,
                      color=ptp_trunk)) +
        facet_wrap(~accuracy_type, nrow = 1) +
        stat_summary(fun=mean, geom="point", shape=20, size=5, 
                     color="red", fill="red") + 
        stat_summary(fun.data = mean_cl_normal,
                     geom = "errorbar",size=1,width=0.1,color='red') +
        theme(legend.position = '') +
        theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
        ggtitle('Overall, last 4 reps') 

```


Also plot different accuracy types, within each condition. Illustrates nicely how the performance grows. 

```{r plot-rough-measures-last-two-differently-grouped, fig.width=13, fig.height=4}

sum_stats_each_participant %>%
        filter(neighbor_status == 'both') %>%
        droplevels() %>%
        ggplot(aes(x=accuracy_type,
                   y=last_two_mean)) +
        geom_violin() +
        geom_dotplot(binaxis = 'y',
                     stackdir = 'center',
                     stackratio = 1,
                     dotsize = 1,
                     fill = 'black',
                     alpha = 0.2) +
        geom_line(aes(group=ptp_trunk,
                      color=ptp_trunk)) +
        facet_wrap(~condition, nrow = 1) +
        stat_summary(fun=mean, geom="point", shape=20, size=5, 
                     color="blue", fill="blue") + 
        stat_summary(fun.data = mean_cl_normal,
                     geom = "errorbar",size=1,width=0.1,color='blue') +
        theme(legend.position = '') +
        theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
        ggtitle('Overall, last 2 reps') 


```

### Landmak vs Non-landmark


```{r plot-rough-measures-last-two-lm-non-lm, fig.width=12, fig.height=4}

sum_stats_each_participant %>%
        filter(neighbor_status != 'both',
               !condition %in% c('random_locations','no_schema')) %>%
        droplevels() %>%
        pivot_wider(id_cols = c(ptp_trunk,
                                condition,
                                accuracy_type),
                    names_from = neighbor_status,
                    values_from = last_two_mean) %>% 
        mutate(neighbor_diff = neighbor - island) %>%
        ggplot(aes(x=condition,y=neighbor_diff)) +
        geom_violin() +
        # geom_jitter(width = 0.1, alpha = 0.2) +
        geom_dotplot(binaxis='y', stackdir='center',
                     stackratio=1, dotsize=1, fill="black",
                     alpha=0.3) +        
        geom_line(aes(group=ptp_trunk,
                      color=ptp_trunk)) +
        stat_summary(fun=mean, geom="point", shape=20, size=5, 
                     color="blue", fill="blue") + 
        stat_summary(fun.data = mean_cl_normal,
                     geom = "errorbar",size=1,width=0.1,color='blue') +        
        facet_wrap(~accuracy_type, nrow = 1) +
        ylab('Diff') + 
        theme(legend.position = '') +
        theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
        ggtitle('Landmark minus non-landmark, last 2')

sum_stats_each_participant %>%
        filter(neighbor_status != 'both',
               !condition %in% c('random_locations','no_schema')) %>%
        droplevels() %>%
        pivot_wider(id_cols = c(ptp_trunk,
                                condition,
                                accuracy_type),
                    names_from = neighbor_status,
                    values_from = last_four_mean) %>% 
        mutate(neighbor_diff = neighbor - island) %>%
        ggplot(aes(x=condition,y=neighbor_diff)) +
        geom_violin() +
        # geom_jitter(width = 0.1, alpha = 0.2) +
        geom_dotplot(binaxis='y', stackdir='center',
                     stackratio=1, dotsize=1, fill="black",
                     alpha=0.3) +        
        geom_line(aes(group=ptp_trunk,
                      color=ptp_trunk)) +
        stat_summary(fun=mean, geom="point", shape=20, size=5, 
                     color="red", fill="red") +   
        stat_summary(fun.data = mean_cl_normal,
                     geom = "errorbar",size=1,width=0.1,color='red') +        
        facet_wrap(~accuracy_type, nrow = 1) +
        ylab('Diff') + 
        theme(legend.position = '') +
        theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
        ggtitle('Landmark minus non-landmark, last 4')
        
        


```

Conclusions from this section:

- Use the average of last 2 reps as the "rough" measure of learning.
- Use correct_exact and correct_one_square_away measures.
- Landmark-vs-non-landmark doesn't seem to show any difference on the plots.

# Other plots?

```{r plot, fig.width=10, fig.height=10, warning=FALSE, message=FALSE}

for (iPart in unique(session_results_all_ptp_long_accuracy$ptp_trunk)[1]){
        print(iPart)
        
        fig_long_accu <- mean_by_rep_all_types_long %>%
                filter(ptp_trunk == iPart) %>%
                droplevels() %>%
                ggplot(aes(x=new_pa_img_row_number_across_sessions,
                           y=correct_mean,
                           color=accuracy_type)) +
                
                # Add the average across toys
                geom_point(aes(shape = neighbor_status)) +
                geom_line(size=1,
                          aes(linetype = neighbor_status)) +
                
                # # Add the average across landmark or not
                # geom_point(data = mean_by_landmark_rep, 
                #            aes(group=adjascent_neighbor,
                #                color=adjascent_neighbor,
                #                y=correct_rad_63_mean)) +
                # geom_line(data = mean_by_landmark_rep, 
                #           aes(group=adjascent_neighbor,
                #               color=adjascent_neighbor,
                #               y=correct_rad_63_mean),
                #           size=1) +
                # 
                facet_grid(accuracy_type~condition) +
                ggtitle(paste(iPart,'; ','Various Accuracy types',sep='')) +
                theme(legend.position = 'top') +
                xlab('Image repetition') +
                scale_x_continuous(breaks=seq(1:8)) + 
                geom_vline(xintercept = 4.5, linetype = 'dashed')
        
        print(fig_long_accu)

}



```

`